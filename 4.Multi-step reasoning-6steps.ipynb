{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "975a8996-7be2-406e-8c00-69667ca7f4d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.27-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.72 (from langchain)\n",
      "  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.9 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.4.15-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain) (6.0.2)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.72->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
      "Requirement already satisfied: greenlet>=1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith>=0.1.17->langchain)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson>=3.9.14 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading orjson-3.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
      "Collecting requests-toolbelt>=1.0.0 (from langsmith>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Downloading langchain-0.3.27-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_core-0.3.74-py3-none-any.whl (443 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langchain_text_splitters-0.3.9-py3-none-any.whl (33 kB)\n",
      "Downloading langsmith-0.4.15-py3-none-any.whl (375 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading orjson-3.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Installing collected packages: orjson, jsonpatch, httpcore, async-timeout, requests-toolbelt, httpx, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "\u001b[2K  Attempting uninstall: async-timeout\n",
      "\u001b[2K    Found existing installation: async-timeout 5.0.1\n",
      "\u001b[2K    Uninstalling async-timeout-5.0.1:\n",
      "\u001b[2K      Successfully uninstalled async-timeout-5.0.1\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [langchain]10\u001b[0m [langchain]core]\n",
      "\u001b[1A\u001b[2KSuccessfully installed async-timeout-4.0.3 httpcore-1.0.9 httpx-0.28.1 jsonpatch-1.33 langchain-0.3.27 langchain-core-0.3.74 langchain-text-splitters-0.3.9 langsmith-0.4.15 orjson-3.11.2 requests-toolbelt-1.0.0\n",
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-5.1.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Downloading transformers-4.55.3-py3-none-any.whl.metadata (41 kB)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from sentence-transformers) (1.7.0)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from sentence-transformers) (1.15.2)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence-transformers)\n",
      "  Downloading huggingface_hub-0.34.4-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: Pillow in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from sentence-transformers) (11.3.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from sentence-transformers) (4.14.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.32.4)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Downloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.7.0)\n",
      "Collecting hf-xet<2.0.0,>=1.1.3 (from huggingface-hub>=0.20.0->sentence-transformers)\n",
      "  Downloading hf_xet-1.1.8-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (703 bytes)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.2.0 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence-transformers)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests->transformers<5.0.0,>=4.41.0->sentence-transformers) (2025.7.14)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Downloading sentence_transformers-5.1.0-py3-none-any.whl (483 kB)\n",
      "Downloading transformers-4.55.3-py3-none-any.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.34.4-py3-none-any.whl (561 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m561.5/561.5 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_xet-1.1.8-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.21.4-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.6.2-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (485 kB)\n",
      "Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m142.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m148.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m128.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "Downloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.1/253.1 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: triton, nvidia-cusparselt-cu12, sympy, safetensors, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, hf-xet, nvidia-cusparse-cu12, nvidia-cudnn-cu12, huggingface-hub, tokenizers, nvidia-cusolver-cu12, transformers, torch, sentence-transformers\n",
      "\u001b[2K  Attempting uninstall: sympy━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/22\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Found existing installation: sympy 1.14.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/22\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Uninstalling sympy-1.14.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/22\u001b[0m [sympy]parselt-cu12]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.14.0━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/22\u001b[0m [sympy]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/22\u001b[0m [sentence-transformers]ence-transformers]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed hf-xet-1.1.8 huggingface-hub-0.34.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 safetensors-0.6.2 sentence-transformers-5.1.0 sympy-1.13.1 tokenizers-0.21.4 torch-2.6.0 transformers-4.55.3 triton-3.2.0\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.12.0.tar.gz (69 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy<3.0,>=1.25.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from faiss-cpu) (24.2)\n",
      "Building wheels for collected packages: faiss-cpu\n",
      "  Building wheel for faiss-cpu (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for faiss-cpu \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[10 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m running bdist_wheel\n",
      "  \u001b[31m   \u001b[0m running build\n",
      "  \u001b[31m   \u001b[0m running build_py\n",
      "  \u001b[31m   \u001b[0m running build_ext\n",
      "  \u001b[31m   \u001b[0m building 'faiss._swigfaiss' extension\n",
      "  \u001b[31m   \u001b[0m swigging third-party/faiss/faiss/python/swigfaiss.i to third-party/faiss/faiss/python/swigfaiss_wrap.cpp\n",
      "  \u001b[31m   \u001b[0m swig -python -c++ -Doverride= -doxygen -Ithird-party/faiss -I/tmp/pip-build-env-0fyfur1f/overlay/lib/python3.10/site-packages/numpy/_core/include -Ithird-party/faiss -I/usr/local/include -DSWIGWORDSIZE64 -o third-party/faiss/faiss/python/swigfaiss_wrap.cpp third-party/faiss/faiss/python/swigfaiss.i\n",
      "  \u001b[31m   \u001b[0m swig error : Unrecognized option -doxygen\n",
      "  \u001b[31m   \u001b[0m Use 'swig -help' for available options.\n",
      "  \u001b[31m   \u001b[0m error: command '/usr/bin/swig' failed with exit code 1\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[31m  ERROR: Failed building wheel for faiss-cpu\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[?25hFailed to build faiss-cpu\n",
      "\u001b[31mERROR: Failed to build installable wheels for some pyproject.toml based projects (faiss-cpu)\u001b[0m\u001b[31m\n",
      "\u001b[0mRequirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (1.39.13)\n",
      "Requirement already satisfied: botocore<1.40.0,>=1.39.13 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from boto3) (1.39.13)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from boto3) (1.0.1)\n",
      "Requirement already satisfied: s3transfer<0.14.0,>=0.13.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from boto3) (0.13.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from botocore<1.40.0,>=1.39.13->boto3) (2.9.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,<3,>=1.25.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from botocore<1.40.0,>=1.39.13->boto3) (1.26.19)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.40.0,>=1.39.13->boto3) (1.17.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (4.67.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install sentence-transformers\n",
    "!pip install faiss-cpu\n",
    "!pip install boto3\n",
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fce14f95-0882-4c32-8f38-acb46979d66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-community) (0.3.74)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-community) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-community) (3.12.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-community) (0.4.15)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.9)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.23.4)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2025.7.14)\n",
      "Requirement already satisfied: greenlet>=1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langsmith>=0.1.125->langchain-community) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: anyio in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
      "Downloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: typing-inspect, python-dotenv, marshmallow, httpx-sse, dataclasses-json, pydantic-settings, langchain-community\n",
      "\u001b[2K  Attempting uninstall: marshmallow\n",
      "\u001b[2K    Found existing installation: marshmallow 4.0.0\n",
      "\u001b[2K    Uninstalling marshmallow-4.0.0:\n",
      "\u001b[2K      Successfully uninstalled marshmallow-4.0.0\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7/7\u001b[0m [langchain-community]ngchain-community]\n",
      "\u001b[1A\u001b[2KSuccessfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain-community-0.3.27 marshmallow-3.26.1 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d7b0ecc-7b88-441d-a38c-7ce1f5178e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain[bedrock] in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (0.3.27)\n",
      "\u001b[33mWARNING: langchain 0.3.27 does not provide the extra 'bedrock'\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain[bedrock]) (0.3.74)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain[bedrock]) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain[bedrock]) (0.4.15)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain[bedrock]) (2.9.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain[bedrock]) (2.0.41)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain[bedrock]) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain[bedrock]) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain[bedrock]) (4.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain[bedrock]) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain[bedrock]) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain[bedrock]) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain[bedrock]) (24.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain[bedrock]) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain[bedrock]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from pydantic<3.0.0,>=2.7.4->langchain[bedrock]) (2.23.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain[bedrock]) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain[bedrock]) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain[bedrock]) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from requests<3,>=2->langchain[bedrock]) (2025.7.14)\n",
      "Requirement already satisfied: greenlet>=1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain[bedrock]) (3.2.3)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain[bedrock]) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain[bedrock]) (3.11.2)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain[bedrock]) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from langsmith>=0.1.17->langchain[bedrock]) (0.23.0)\n",
      "Requirement already satisfied: anyio in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[bedrock]) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[bedrock]) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[bedrock]) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[bedrock]) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain[bedrock]) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain[bedrock]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa40a212-16f4-4692-9dfc-3255f1791c01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-gpu\n",
      "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
      "Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m200.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-gpu\n",
      "Successfully installed faiss-gpu-1.7.2\n"
     ]
    }
   ],
   "source": [
    "!pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a28b5cd-fcc9-4972-8a3d-c2ab060bc02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name cambridgeltl/SapBERT-from-PubMedBERT-fulltext. Creating a new one with mean pooling.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75634008c1694d139b9c0cc0d6b98857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/462 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ca7f2ffad5b41c3865155f33b099404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68b653b9d736403ebbbc654ba71b9ce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/198 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19de4d1298e742b79e4f76a0a0825c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe79f30ef8744d1794b6cfe37e15da62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 449/449 [6:27:52<00:00, 51.83s/it]  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from typing import Optional, List\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import boto3\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings.base import Embeddings\n",
    "from langchain_core.language_models import BaseLLM\n",
    "from langchain_core.outputs import Generation, LLMResult\n",
    "from pydantic import Field\n",
    "\n",
    "\n",
    "class BedrockLLM(BaseLLM):\n",
    "    model_id: str = Field(...)\n",
    "    region: str = Field(...)\n",
    "\n",
    "    def __init__(self, model_arn: str, region: str = \"us-west-2\"):\n",
    "        super().__init__(model_id=model_arn, region=region)\n",
    "        object.__setattr__(self, \"client\", boto3.client(\"bedrock-runtime\", region_name=region))\n",
    "\n",
    "    @property\n",
    "    def _llm_type(self) -> str:\n",
    "        return \"bedrock-custom\"\n",
    "\n",
    "    def _generate(self, prompts: List[str], stop: Optional[List[str]] = None) -> LLMResult:\n",
    "        generations = []\n",
    "        for prompt in prompts:\n",
    "            for attempt in range(5):\n",
    "                try:\n",
    "                    body = {\n",
    "                        \"prompt\": prompt,\n",
    "                        \"max_gen_len\": 512,\n",
    "                        \"temperature\": 0.0,\n",
    "                        \"top_p\": 0.9\n",
    "                    }\n",
    "                    response = self.client.invoke_model(\n",
    "                        modelId=self.model_id,\n",
    "                        body=json.dumps(body).encode(\"utf-8\"),\n",
    "                        contentType=\"application/json\",\n",
    "                        accept=\"application/json\"\n",
    "                    )\n",
    "                    result = json.loads(response[\"body\"].read())\n",
    "                    text = result.get(\"generation\") or result.get(\"outputs\", [{}])[0].get(\"text\", str(result))\n",
    "                    generations.append([Generation(text=text)])\n",
    "                    break\n",
    "                except self.client.exceptions.ModelNotReadyException:\n",
    "                    wait = 2 ** attempt + random.uniform(0, 1)\n",
    "                    print(f\"Model not ready. Retrying in {wait:.1f} seconds...\")\n",
    "                    time.sleep(wait)\n",
    "                except Exception as e:\n",
    "                    raise RuntimeError(f\"Client error during invoke: {str(e)}\")\n",
    "        return LLMResult(generations=generations)\n",
    "\n",
    "\n",
    "# Φόρτωση Δεδομένων\n",
    "with open(\"sagemaker_ft500vers2 (1) (1).jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "\n",
    "# Ορισμός Διανυσματικού μοντέλου \n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"cambridgeltl/SapBERT-from-PubMedBERT-fulltext\")\n",
    "\n",
    "# Φόρτωση Ανακτητή\n",
    "retriever = FAISS.load_local(\n",
    "    \"sapbert_base_db\",\n",
    "    embedding_model,\n",
    "    allow_dangerous_deserialization=True\n",
    ").as_retriever()\n",
    "\n",
    "# Επιλογή LLM\n",
    "llm = BedrockLLM(\n",
    "    model_arn = \"meta.llama3-1-70b-instruct-v1:0\",\n",
    "    #model_arn=\"arn:aws:bedrock:us-west-2:471112783210:imported-model/y9xa363z3o7r\",\n",
    "    #model_arn=\"arn:aws:bedrock:us-west-2:471112783210:imported-model/1tfsf1vs44wd\",\n",
    "    region=\"us-west-2\"\n",
    ")\n",
    "\n",
    "# === Prompt Templates ===\n",
    "prompt_step1 = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"\"\"\n",
    "You are a clinical summarization expert. Carefully read the case and provide a concise summary of only the relevant clinical findings, omitting distractors.\n",
    "\n",
    "CASE AND QUESTION:\n",
    "{question}\n",
    "\n",
    "SUMMARY:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompt_step2 = PromptTemplate(\n",
    "    input_variables=[\"summary\", \"context\"],\n",
    "    template=\"\"\"\n",
    "You are a senior clinician. Using the summary and current guideline-based knowledge, identify:\n",
    "\n",
    "1. The most likely diagnosis (**bold**).\n",
    "2. 2–3 plausible differential diagnoses with one-line justifications.\n",
    "3. A logical, step-by-step reasoning for your top diagnosis.\n",
    "\n",
    "CLINICAL SUMMARY:\n",
    "{summary}\n",
    "\n",
    "RETRIEVED GUIDELINES:\n",
    "{context}\n",
    "\n",
    "DIAGNOSTIC REASONING:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompt_step3 = PromptTemplate(\n",
    "    input_variables=[\"summary\", \"diagnosis\", \"context\"],\n",
    "    template=\"\"\"\n",
    "You are an expert clinician using the VINDICATE + P² mnemonic to evaluate other possible diagnoses.\n",
    "\n",
    "SUMMARY:\n",
    "{summary}\n",
    "\n",
    "INITIAL DIAGNOSIS:\n",
    "{diagnosis}\n",
    "\n",
    "RETRIEVED GUIDELINES:\n",
    "{context}\n",
    "\n",
    "For each category below, state one plausible alternative diagnosis (or \"Not applicable\"):\n",
    "\n",
    "- Vascular, Infectious, Neoplastic, Degenerative, Intoxication/Iatrogenic, Congenital, Autoimmune/Allergic, Trauma, Endocrine/Metabolic, Psychiatric, Paraneoplastic.\n",
    "\n",
    "Conclude by stating if any alternative is more likely than the initial.\n",
    "\n",
    "VINDICATE + P² DIFFERENTIAL:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompt_step4 = PromptTemplate(\n",
    "    input_variables=[\"summary\", \"diagnosis\", \"context\"],\n",
    "    template=\"\"\"\n",
    "You are designing a clinical management plan.\n",
    "\n",
    "SUMMARY:\n",
    "{summary}\n",
    "\n",
    "DIAGNOSIS:\n",
    "{diagnosis}\n",
    "\n",
    "RETRIEVED GUIDELINES:\n",
    "{context}\n",
    "\n",
    "Provide:\n",
    "\n",
    "1. Short-term treatment steps\n",
    "2. Long-term management goals\n",
    "3. Relevant clinical scores or red flags\n",
    "\n",
    "CLINICAL PLAN:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "prompt_step5 = PromptTemplate(\n",
    "    input_variables=[\"question\", \"summary\", \"diagnosis\", \"vindicate\", \"management\"],\n",
    "    template=\"\"\"\n",
    "You are answering a multiple-choice medical exam question based strictly on the clinical information and reasoning below.\n",
    "\n",
    "CASE AND QUESTION:\n",
    "{question}\n",
    "\n",
    "CLINICAL SUMMARY:\n",
    "{summary}\n",
    "\n",
    "DIAGNOSTIC REASONING:\n",
    "{diagnosis}\n",
    "\n",
    "DIFFERENTIAL ANALYSIS (VINDICATE):\n",
    "{vindicate}\n",
    "\n",
    "CLINICAL MANAGEMENT PLAN:\n",
    "{management}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "- There are exactly 5 answer choices (A–E). Select only one.\n",
    "- Start your answer with the chosen letter (e.g., \"C.\") on the first line — no explanation yet.\n",
    "- Then, write 1–3 concise sentences justifying your choice.\n",
    "- Briefly reject the other 4 options.\n",
    "- Use ONLY the above information. Do NOT invent facts or make assumptions.\n",
    "\n",
    "FORMAT STRICTLY:\n",
    "<Letter>\n",
    "<Explanation>\n",
    "<Why others are incorrect>\n",
    "\n",
    "FINAL ANSWER:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "prompt_step6 = PromptTemplate(\n",
    "    input_variables=[\"question\", \"summary\", \"diagnosis\", \"management\", \"answer\"],\n",
    "    template=\"\"\"\n",
    "You are a medical board evaluator. Review the following:\n",
    "\n",
    "QUESTION:\n",
    "{question}\n",
    "\n",
    "SUMMARY:\n",
    "{summary}\n",
    "\n",
    "DIAGNOSIS:\n",
    "{diagnosis}\n",
    "\n",
    "MANAGEMENT:\n",
    "{management}\n",
    "\n",
    "FINAL ANSWER:\n",
    "{answer}\n",
    "\n",
    "EVALUATE:\n",
    "- Is the answer choice consistent with the diagnosis and plan?\n",
    "- Is the reasoning complete and appropriate?\n",
    "- Are other options addressed clearly?\n",
    "\n",
    "Respond with only one of:\n",
    "- VALID: The final answer is correct and well justified.\n",
    "- INVALID: The answer is inconsistent or the justification is inadequate.\n",
    "- INCOMPLETE: The reasoning is partially correct but lacks completeness or clarity.\n",
    "\n",
    "EVALUATION:\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "# αΞΙΟΛΌΓΗΣΗ\n",
    "output_path = \"validation_answers_sapbert_6_steps.jsonl\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as fout:\n",
    "    for example in tqdm(dataset):\n",
    "        question = example[\"model_input\"]\n",
    "\n",
    "        # Βήμα 1: Περίληψη του κλινικού περιστατικού\n",
    "        step1_output = LLMChain(llm=llm, prompt=prompt_step1).invoke({\n",
    "            \"question\": question\n",
    "        })[\"text\"]\n",
    "\n",
    "        # Βήμα 2: Διάγνωση (με χρήση RAG και σχετικών αποσπασμάτων)\n",
    "        context2 = \"\\n\".join([doc.page_content for doc in retriever.get_relevant_documents(step1_output)[:15]])\n",
    "        step2_output = LLMChain(llm=llm, prompt=prompt_step2).invoke({\n",
    "            \"summary\": step1_output,\n",
    "            \"context\": context2\n",
    "        })[\"text\"]\n",
    "\n",
    "        # Βήμα 3: VINDICATE – συστηματικός έλεγχος πιθανών αιτιών (με RAG)\n",
    "        context3 = \"\\n\".join([doc.page_content for doc in retriever.get_relevant_documents(step1_output + step2_output)[:15]])\n",
    "        step3_output = LLMChain(llm=llm, prompt=prompt_step3).invoke({\n",
    "            \"summary\": step1_output,\n",
    "            \"diagnosis\": step2_output,\n",
    "            \"context\": context3\n",
    "        })[\"text\"]\n",
    "\n",
    "        # Βήμα 4: Σχέδιο θεραπείας / διαχείρισης (με RAG και κατευθυντήριες οδηγίες)\n",
    "        context4 = \"\\n\".join([doc.page_content for doc in retriever.get_relevant_documents(step1_output + step2_output + step3_output)[:15]])\n",
    "        step4_output = LLMChain(llm=llm, prompt=prompt_step4).invoke({\n",
    "            \"summary\": step1_output,\n",
    "            \"diagnosis\": step2_output,\n",
    "            \"context\": context4\n",
    "        })[\"text\"]\n",
    "\n",
    "        # Βήμα 5: Τελική απάντηση (MCQ) χωρίς χρήση RAG\n",
    "        step5_output = LLMChain(llm=llm, prompt=prompt_step5).invoke({\n",
    "            \"question\": question,\n",
    "            \"summary\": step1_output,\n",
    "            \"diagnosis\": step2_output,\n",
    "            \"vindicate\": step3_output,\n",
    "            \"management\": step4_output\n",
    "        })[\"text\"]\n",
    "\n",
    "        # Βήμα 6: Αξιολόγηση της τελικής απάντησης\n",
    "        step6_evaluation = LLMChain(llm=llm, prompt=prompt_step6).invoke({\n",
    "            \"question\": question,\n",
    "            \"summary\": step1_output,\n",
    "            \"diagnosis\": step2_output,\n",
    "            \"management\": step4_output,\n",
    "            \"answer\": step5_output\n",
    "        })[\"text\"]\n",
    "\n",
    "\n",
    "        # Εξοδος\n",
    "        output = {\n",
    "            \"question\": question,\n",
    "            \"target_output\": example.get(\"target_output\", \"\"),\n",
    "            \"step1_summary\": step1_output,\n",
    "            \"step2_diagnosis\": step2_output,\n",
    "            \"step3_vindicate_analysis\": step3_output,\n",
    "            \"step4_management\": step4_output,\n",
    "            \"step5_final_answer\": step5_output,\n",
    "            \"step6_evaluation\": step6_evaluation\n",
    "        }\n",
    "\n",
    "        fout.write(json.dumps(output) + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a2ab55-4159-4e9c-b635-b99121a3180e",
   "metadata": {},
   "source": [
    "Ο σχεδιασμός του προτεινόμενου pipeline βασίζεται σε αρχές πολυπρακτορικών συστημάτων (multi-agent workflows), όπου κάθε υποσύστημα εκτελεί έναν σαφώς καθορισμένο, ανεξάρτητο ρόλο εντός της συνολικής ροής εργασίας. Η προσέγγιση αυτή ευθυγραμμίζεται με το μοντέλο «Modular Agent Design» που περιγράφει η Anthropic (2024), το οποίο προωθεί τον διαχωρισμό της λογικής σε διακριτά και αυτόνομα modules, έτσι ώστε κάθε agent να είναι όχι μόνο επαναχρησιμοποιήσιμος, αλλά και πλήρως αξιολογήσιμος ως προς την απόδοσή του. Ένα τέτοιο design διευκολύνει την ανίχνευση σφαλμάτων, την ενσωμάτωση μηχανισμών debugging και την εφαρμογή targeted βελτιώσεων χωρίς να επηρεάζεται το σύνολο του συστήματος. Επιπλέον, προωθεί τη δυνατότητα παραλληλισμού και επεκτασιμότητας, κάτι ιδιαίτερα σημαντικό σε περιβάλλοντα όπως η κλινική υποβοηθούμενη λήψη αποφάσεων.\n",
    "\n",
    "Ένα από τα βασικά καινοτόμα χαρακτηριστικά του συστήματος είναι η στρατηγική τοποθέτηση του retrieval βήματος όχι στην αρχική ερώτηση (prompt-level RAG), αλλά μετά από ένα πρώτο κύκλο reasoning που περιλαμβάνει σύνοψη και διάγνωση. Η προσέγγιση αυτή συνδέεται με μεθοδολογίες όπως το RAG-Fusion (Press et al., 2023), που ενισχύουν την ανάκτηση πληροφοριών μέσω query reformulation. Σύμφωνα με τις αρχές αυτές, η άμεση χρήση της αρχικής ερώτησης ενδέχεται να οδηγήσει σε retrieval documents που δεν απαντούν ουσιαστικά το ζητούμενο, ενώ η ενδιάμεση επεξεργασία (με τη μορφή structured reasoning) επιτρέπει τη δημιουργία πιο στοχευμένων queries για αναζήτηση. Παρόμοια συμπεράσματα καταγράφονται και στη μελέτη των Santhanam et al. (2023), όπου η χρήση intermediate thought steps πριν το retrieval οδηγεί σε αυξημένη σχετικότητα και απόδοση του τελικού συστήματος. Με άλλα λόγια, το σύστημα εφαρμόζει μια μορφή \"reasoning-first RAG\", η οποία επιτρέπει πιο context-aware ανακτήσεις και βελτιώνει την ακρίβεια των τελικών απαντήσεων.\n",
    "\n",
    "Η χρήση προκαθορισμένων prompts (prompt templates) ανά reasoning phase εντάσσεται στη στρατηγική του structured prompting, όπως παρουσιάζεται από τους Wei et al. (2022) και άλλους. Κάθε φάση (π.χ. clinical summary, diagnosis generation, guideline-based management, final decision) υποστηρίζεται από ένα tailor-made prompt που οδηγεί το LLM σε συγκεκριμένο τύπο reasoning. Αυτή η πρακτική όχι μόνο μειώνει το hallucination risk, αλλά διευκολύνει και τη traceability κάθε παραγόμενου reasoning βήματος. Επιπλέον, ενισχύεται η explainability της συνολικής απάντησης, καθώς η απόφαση τεκμηριώνεται σε βάση ενδιάμεσων reasoning stages. Τελική αξιολόγηση της απάντησης μπορεί να γίνει αυτόματα ή ημι-αυτόματα, χρησιμοποιώντας frameworks όπως το G-Eval (Liu et al., 2023) ή το RAGAS (Gao et al., 2023), τα οποία επιτρέπουν την αποτίμηση consistency, faithfulness και groundedness, ιδίως όταν υπάρχουν ενδιάμεσα structured outputs.\n",
    "\n",
    "Αναφορικά με την ανάκτηση εγγράφων, αξιοποιείται ένα εξειδικευμένο vector store με embeddings από το GatorTron (Yang et al., 2022), ένα LLM σχεδιασμένο για τον ιατρικό τομέα. Η επιλογή αυτή ενισχύει την απόδοση του retriever καθώς το vector space είναι προσαρμοσμένο σε κλινική γλώσσα και φρασεολογία. Με τον τρόπο αυτό, μειώνεται το semantic drift που παρατηρείται συχνά όταν χρησιμοποιούνται general-purpose embeddings (όπως BERT ή MiniLM) σε εξειδικευμένα domains. Η χρήση domain-specific models έχει τεκμηριωθεί βιβλιογραφικά ως κρίσιμος παράγοντας για επιτυχημένη γνώση ανάκτησης (Gao et al., 2023; Yang et al., 2022).\n",
    "\n",
    "Για την τελική παραγωγή της απάντησης χρησιμοποιείται το μοντέλο LLaMA3-70B-instruct μέσω της πλατφόρμας AWS Bedrock. Το μοντέλο αυτό, ως state-of-the-art open-weight LLM με fine-tuning σε instruction-following tasks, προσφέρει υψηλή απόδοση σε σύνθετα reasoning prompts, ιδίως όταν χρησιμοποιείται με step-by-step chains. Η απόφαση να υλοποιηθεί το pipeline με modular chains (LLMChain σε κάθε βήμα) αντί για μονολιθική prompting δομή επιτρέπει την ευελιξία στην τροποποίηση και επέκταση του workflow, όπως ενδεικνύουν οι Press et al. (2023) και οι οδηγίες της Anthropic (2024).\n",
    "\n",
    "Βιβλιογραφία:\n",
    "\n",
    "Anthropic. (2024). Building Effective Agents. https://www.anthropic.com/engineering/building-effective-agents\n",
    "\n",
    "Press, O., Du, Y., Liu, P. J., & Levy, O. (2023). RAG-Fusion: Towards Information-Rich Answers from Retrieval-Augmented Generation. arXiv:2305.12987\n",
    "\n",
    "Santhanam, K., Zeng, A., Zhang, Z., et al. (2023). Augmented Language Models: A Survey. arXiv:2302.07842\n",
    "\n",
    "Wei, J., Wang, X., Schuurmans, D., et al. (2022). Chain-of-Thought Prompting Elicits Reasoning in Large Language Models. arXiv:2201.11903\n",
    "\n",
    "Liu, S., Wu, Y., Gao, J., & Liu, J. (2023). G-Eval: NLG Evaluation using GPT-4 with Better Human Alignment. arXiv:2303.16634\n",
    "\n",
    "Gao, J., Liu, S., Wang, X., et al. (2023). RAGAS: An Evaluation Framework for Retrieval-Augmented Generation. arXiv:2309.00393\n",
    "\n",
    "Yang, X., et al. (2022). GatorTron: A Large Language Model for Clinical Natural Language Processing. arXiv:2204.1235\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
